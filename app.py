#
from fastapi import FastAPI, HTTPException, Query, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import requests
import json
#from db_control import crud, mymodels
from db_control import crud, mymodels_MySQL as mymodels
import openai
#from google import genai
import os
from dotenv import load_dotenv
from datetime import datetime
from gpt_parser import parse_utterance
from sqlalchemy.orm import sessionmaker
from db_control.connect_MySQL import engine
from db_control.mymodels_MySQL import MilkLog

# SQLAlchemy ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æº–å‚™
SessionLocal = sessionmaker(bind=engine, autoflush=False, autocommit=False)

class Customer(BaseModel):
    customer_id: str
    customer_name: str
    age: int
    gender: str

# .env ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼å–å¾—
api_key = os.getenv("OPENAI_API_KEY")
# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
client = openai.OpenAI(api_key=api_key)


# # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰Gemini APIã‚­ãƒ¼å–å¾—
# gemini_api_key = os.getenv("GEMINI_API_KEY")
# # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
# client_gemini = genai.Client(api_key="GEMINI_YOUR_API_KEY")

app = FastAPI()

# CORSãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

#éŸ³å£°èªè­˜ã®æ–¹
class RecordIn(BaseModel):
    utterance: str
    recorded_at: datetime


@app.get("/")
def index():
    return {"message": "FastAPI top page!"}


@app.post("/customers")
def create_customer(customer: Customer):
    values = customer.dict()
    tmp = crud.myinsert(mymodels.Customers, values)
    result = crud.myselect(mymodels.Customers, values.get("customer_id"))

    if result:
        result_obj = json.loads(result)
        return result_obj if result_obj else None
    return None


@app.get("/customers")
def read_one_customer(customer_id: str = Query(...)):
    result = crud.myselect(mymodels.Customers, customer_id)
    if not result:
        raise HTTPException(status_code=404, detail="Customer not found")
    result_obj = json.loads(result)
    return result_obj[0] if result_obj else None


@app.get("/allcustomers")
def read_all_customer():
    result = crud.myselectAll(mymodels.Customers)
    # çµæœãŒNoneã®å ´åˆã¯ç©ºé…åˆ—ã‚’è¿”ã™
    if not result:
        return []
    # JSONæ–‡å­—åˆ—ã‚’Pythonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
    return json.loads(result)


@app.put("/customers")
def update_customer(customer: Customer):
    values = customer.dict()
    values_original = values.copy()
    tmp = crud.myupdate(mymodels.Customers, values)
    result = crud.myselect(mymodels.Customers, values_original.get("customer_id"))
    if not result:
        raise HTTPException(status_code=404, detail="Customer not found")
    result_obj = json.loads(result)
    return result_obj[0] if result_obj else None


@app.delete("/customers")
def delete_customer(customer_id: str = Query(...)):
    result = crud.mydelete(mymodels.Customers, customer_id)
    if not result:
        raise HTTPException(status_code=404, detail="Customer not found")
    return {"customer_id": customer_id, "status": "deleted"}


@app.get("/fetchtest")
def fetchtest():
    response = requests.get('https://jsonplaceholder.typicode.com/users')
    return response.json()

#ã‚ªã‚¦ãƒ è¿”ã—æ©Ÿèƒ½(ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’ãã®ã¾ã¾è¿”ã™)
@app.post("/echo")
async def echo(request: Request):
    data = await request.json()
    message = data.get("message", "")
    return {"echo": message}

#AIã§å†…å®¹ã‚’è¦ç´„ã—ã€æœ¬äººã®ã‚„ã‚ŠãŸã„ã“ã¨ã€Willã‚’ææ¡ˆã™ã‚‹
@app.post("/ai_gpt")
async def ask_openai(request: Request):
    data = await request.json()
    user_message = data.get("message", "")
    prompt = f"""
        ä»Šæ—¥ã®æ—¥è¨˜ã‚„æ°—æŒã¡ã‚’ã€Œ{user_message}ã€ã¨ã—ã¦è¨˜ã—ã¾ã—ãŸã€‚
        ã“ã®å†…å®¹ã‹ã‚‰ã€ä»¥ä¸‹ã®é …ç›®ã‚’æ—¥æœ¬èªã§1ï½2è¡Œã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
        - æ½œåœ¨çš„ã«ã‚„ã‚ŠãŸã„ã“ã¨ã€æ°—æŒã¡ãŒå‘ã„ã¦ã„ã‚‹ã‚‚ã®ï¼ˆWill Can Mustã®Willã«ã‚ãŸã‚‹ã‚‚ã®ï¼‰
        """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ç›¸æ‰‹ã®æ–‡ç« ã‹ã‚‰æ°—æŒã¡ã‚„ç§˜ã‚ãŸã‚‹æ„æ€ã‚’æ±²ã¿å–ã‚‹ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=300,
            temperature=0.7
        )

        ai_reply = response.choices[0].message.content.strip()
        return {"ai_response": ai_reply}

    except Exception as e:
        return {"error": str(e)}


@app.post("/api/record")
async def record_feed(body: RecordIn):
# === 1) GPT ã§æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— ===
    parsed = await parse_utterance(body.utterance, body.recorded_at.isoformat())
    # parsed ãŒã©ã‚“ãªè¾æ›¸ã«ãªã£ã¦ã„ã‚‹ã‹ãƒ­ã‚°å‡ºåŠ›
    print("ğŸ£ GPT ã§æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿:", parsed)

# === 2) parsed ã® timestamp ã‚’ datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ› ===
    ts_str = parsed.get("timestamp")
    try:
        # æœ«å°¾ã« "Z" ãŒã¤ã„ã¦ã„ã‚‹å ´åˆã€"+00:00" ã«ç½®ãæ›ãˆã¦ã‹ã‚‰ fromisoformat ã§ UTC ã¨ã—ã¦æ‰±ã†
        ts = datetime.fromisoformat(ts_str.replace("Z", "+00:00"))
    except Exception:
        # ã‚‚ã—ä¸æ­£ãªå½¢å¼ãªã‚‰ã€API ã«é€ã‚‰ã‚Œã¦ããŸ recorded_atï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡æ™‚åˆ»ï¼‰ã‚’ä½¿ã†
        ts = body.recorded_at

# === 3) SQLAlchemy ã§ DB ã« INSERT ===
    session = SessionLocal()
    try:
        new_log = MilkLog(
            milktype   = parsed.get("milktype", "ä¸æ˜"),
            volume     = parsed.get("volume", 0),
            created_at = ts
        )
        session.add(new_log)
        session.commit()
    except Exception as e:
        session.rollback()
        print("ğŸ”´ DB ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
        raise HTTPException(status_code=500, detail="DB ä¿å­˜ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
    finally:
        session.close()

    # === 4) ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™ ===
    return {"parsed": parsed, "saved": True}





#         #AIã§å†…å®¹ã‚’è¦ç´„ã—ã€æœ¬äººã®ã‚„ã‚ŠãŸã„ã“ã¨ã€Willã‚’ææ¡ˆã™ã‚‹
# @app.post("/ai_gemini")
# async def ask_gemini(request: Request):
#     data = await request.json()
#     user_message = data.get("message", "")
#     prompt = f"""
#         ã‚ãªãŸã¯ç›¸æ‰‹ã®æ–‡ç« ã‹ã‚‰æ°—æŒã¡ã‚„ç§˜ã‚ãŸã‚‹æ„æ€ã‚’æ±²ã¿å–ã‚‹ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚
#         ä»Šæ—¥ã®æ—¥è¨˜ã‚„æ°—æŒã¡ã‚’ã€Œ{user_message}ã€ã¨ã—ã¦è¨˜ã—ã¾ã—ãŸã€‚
#         ã“ã®å†…å®¹ã‹ã‚‰ã€ä»¥ä¸‹ã®é …ç›®ã‚’æ—¥æœ¬èªã§1ï½2è¡Œã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
#         - æ½œåœ¨çš„ã«ã‚„ã‚ŠãŸã„ã“ã¨ã€æ°—æŒã¡ãŒå‘ã„ã¦ã„ã‚‹ã‚‚ã®ï¼ˆWill Can Mustã®Willã«ã‚ãŸã‚‹ã‚‚ã®ï¼‰
#         """
    
#     try:
#         response = client_gemini.models.generate_content(
#             model="gemini-2.0-flash",
#             contents=prompt
#         )
#         return {"ai_response": response.text.strip()}

#     except Exception as e:
#         return {"error": str(e)}
    
#milklogã«ã‚¤ãƒ³ã‚µãƒ¼ãƒˆã™ã‚‹